== Principles
=== Trunk Based Development (Branching)
Trunk-based development (TBD) is a source-control branching model for software development where developers merge every new feature, bug fix, or other code changes to one central branch in the version control system. This branch is called “trunk”. TBD enables continuous integration – and, by extension, continuous delivery – by creating an environment where commits to trunk naturally occur multiple times daily for each programmer. This makes it easy to satisfy the “everyone on the development team commits to trunk at least every 24 hours” requirement of continuous integration and lays the foundation for the codebase to be releasable at any time, as it is necessary for continuous delivery and continuous deployment.
Let’s have a look at the trunk-based development workflow.

++++
<iframe style="border:none" width="100%" height="900px" src="https://whimsical.com/embed/95zX1zeN2DCPYAo4an3xXz"></iframe>
++++

Typically we use  **Scaled Trunk-Based Development**

==== Best Practices
* Use only fast-forward merges to trunk.
* Disallow pushing to trunk.
* Write machine-readable commit messages.
* _Merge squash your multiple changes in your short life branches._
* _The best practice is to rebase master against your short-lived branch to keep it up to date. Do NOT merge master back to your short-lived branch and then again to trunk, to avoid multiple merge comments and confusing history._
*  Feature branches must be short-lived.
*  If you are working with a ticketing system, make sure you add the ticket number to each commit.
* Keep your commit messages as concise as possible.
* _Avoid hotfixes. Fixing forward is better than rolling back. If you don't want to include another feature that has been released, disable it with feature flags. Remember, you want to keep the flow of updates and releases as short and constant as possible, the hotfix will only complicate your repo._
*  Try to understand git commands and internals before using graphic tools like git "Kraken". They can be very helpful, especially when looking at history graphs. However, you still need to learn certain basic things like the difference between revert and reset.
* Don't ever commit secrets of any kind to the repository  -**EVER**.

NOTE: For more information, see https://trunkbaseddevelopment.com/[here] and https://medium.com/factualopinions/git-to-know-this-before-you-do-trunk-based-development-tbd-476bc8a7c22f[here]

=== Quality Gateway
The **Quality Gateway** is an organizational\infrastructure point for testing code. 
The purpose of a quality gateway is to trap incorrect code and bugs as early as possible to prevent getting the incorrect code from the local codebase into a shared codebase.
To get through the quality gateway, the code must satisfy several <<tests>>.
The tests are devised to make sure that each requirement meets business needs.

==== Quality Gates

* Verification of component versions `local`.
* Code Compilation `local`.
* <<small-test>> `local`.
* Static analysis `local`.
* <<medium-test>> `local`.
* Code Compilation `remote`.
* Static analysis `remote`.
* <<medium-test>> `remote`. _Optional if acceptable by 10 minutes rule_
* <<large-test>> `remote`.

[[tests]]
=== Test (Test case)
The **test case** is a specification of the inputs, execution conditions, testing procedure, and expected results that
define a single test to be executed to achieve a particular software testing objective. For example, to exercise a particular
program path or to verify compliance with a specific requirement. Test cases underlie testing that is methodical rather than haphazard.
A battery of test cases can be built to produce the desired coverage of the software being tested.
Formally defined test cases allow the same tests to be run repeatedly against successive versions of the software,
allowing for effective and consistent regression testing.

Google practices the language of the small, medium, and large tests, featuring scope over form,
instead of marking between code, integration, and system testing.
According to the book https://www.amazon.com/Google-Tests-Software-James-Whittaker/dp/0321803027[How Google Tests Software], we define three types of test:

* <<small-test>> - covers a single unit of code in a completely faked environment. `unit` tests
* <<medium-test>> - covers multiple and interacting units of code in a faked environment. `integration`, `capability` tests
* <<large-test>> - covers any number of units of code in the real integrated environment close to production environment with real and not faked resources.
`E2E`, `Smoke`, `Sanity`, `Functional`, `NFR` tests

[[small-test]]
==== Small Tests
**Small tests** execute the code within a single function or module.
The focus is on typical functional issues, data corruption, error conditions, and off-by-one mistakes.
_Small tests are of short duration, usually running in seconds or less._

**Small Tests** are **Unit Tests** in testing terminology.

They are most likely written by an <<roles-swe, SWE>>, less often by a <<roles-set, SETs>>,
and hardly ever by <<roles-tes, TEs>>. Small tests usually require mocks and faked environments to run.
(Mocks and fakes are stubs—substitutes for actual functions—that act as placeholders for dependencies that might not exist,
are too buggy to be reliable, or too difficult to emulate error conditions.) [TEs](https://github.com/vitech-team/SDLC/wiki/Glossary)
rarely write small tests but might run them when they are trying to diagnose a particular failure.

Small tests try to answer the following question: **"Does this code do what it is supposed to do?"**.

_Running of small tests is usually required during **test** build phase in **Continuous Integration** pipeline._

IMPORTANT: A test that doesn't require dependency on external resources (file system, database, network, http://wiremock.org[wiremocks], another OS process) is a small one.

[[medium-test]]
==== Medium Tests
**Medium tests** are regularly automated and involve two or more interacting features.
_The focus is on testing the directly interaction between features_, so-called nearest neighbor functions. <<roles-set, SETs>> supports the development of medium tests as completed individual features early in the product cycle and <<roles-swe, SWEs>> is heavily involved in writing, debugging, and maintaining the actual tests.
If a medium test fails or breaks, the developer takes care of it autonomously.

In a majority of cases <<medium-test>> reflect **Integration Tests** in testing terminology.

Later in the development cycle, <<roles-tes, TEs>> can execute medium tests either manually (if the test is difficult to automate) or with automation.

Medium tests try to answer the following question: **"Does a set of near neighbor functions interoperate with each other the way they are supposed to?"**

The following neighbor functions can be used for a specific function under test: **another component, module, network interface, file system, database, message broker, storage, etc**.
In the majority of cases, medium tests rely on an external process running on the same host/VM/container.
A good example of an external process is a docker service running on the same host/VM with a test-runner process, which can be utilized by https://www.testcontainers.org/[testcontainers] framework.

_Medium Tests must be separated from Small Tests in a project structure.
Running of medium tests is usually required during **integration-test** build phase in **Continuous Integration** pipeline.
Test Coverage tools should have separate reports for Medium Tests._

**It's expected that medium tests shouldn't run longer than 5-10 minutes. The majority of time is usually spent on a dependent process start, but once they are running - tests should complete fast.**

[[large-test]]
==== Large Tests

**Large tests** are usually running over component(s) deployed to the environment by the same **Continuous Deployment** pipeline that deploys to production.

**Large Tests** can be reflected by the following test suites:

* End-To-End
* Functional
* Load/Stress/Performance (NFR gates)
* Security
* Smoke/Sanity
* Any other tests which are running over deployed components

Large tests try to answer the following question: **“Does the product operate the way a user expects (from functional and non-functional requirements perspective) and produce the desired results?”**.

Large Tests need more time to run than medium tests, they rely on a full PROD-like deployment alongside real (not stubbed/mocked) infrastructure services.

Running of **Large Tests** can be required in the following phases/places:

* Pull Requests checks (if they are fast enough and overall PR time doesn't go beyond ~15mins).
* Functional Test Suite in **Continuous Deployment** pipeline (after-deployment step).
If their run takes too long -- it's expected to have separate **Smoke/Sanity test suite** extracted for that purpose, and running of Functional tests can be executed by separate pipeline.
* NFRs gate in **Continuous Deployment** pipeline. It's expected that desired/existed application benchmarks have
been already collected by performance tests and put as an NFR's thresholds/gates. Metrics collected during NFR gate tests have to be trended in time.

=== Versions
https://semver.org[Semantic Versioning]

Given a version number `MAJOR.MINOR.PATCH`, increment the:

* *MAJOR* - version when you make incompatible API changes.
* *MINOR* - version when you add functionality in a backward compatible manner.
* *PATCH* - version when you make backward compatible bug fixes.

Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.

Example:
----
1.0.0-alpha < 1.0.0-alpha.1 < 1.0.0-alpha.beta < 1.0.0-beta < 1.0.0-beta.2 < 1.0.0-beta.11 < 1.0.0-rc.1 < 1.0.0.
----

Version change should be driven by commit messages. See examples: https://www.conventionalcommits.org/en/v1.0.0/[Conventional Commits]

[[roles]]
=== Roles
* [[roles-swe]]**SWE** -Software Engineer.
* [[roles-set]]**SET** -Software engineer in Testing is responsible for the complete design and maintenance of the test cases.
* [[roles-tes]]**TEs** -Test engineers.
